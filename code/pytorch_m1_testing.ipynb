{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something\n"
     ]
    }
   ],
   "source": [
    "print(\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8833, 0.1793, 0.9218],\n",
      "        [0.8408, 0.2123, 0.5323],\n",
      "        [0.5581, 0.2310, 0.7946],\n",
      "        [0.8700, 0.1769, 0.7497],\n",
      "        [0.1971, 0.3898, 0.8916]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'batched_dot_mul_sum' from '__main__' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4k/y4ljh2217c57vl68z1zkl0440000gn/T/ipykernel_49379/927675702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     globals={'x': x})\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/utils/benchmark/utils/timer.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_torch_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# Warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             return common.Measurement(\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_m1/lib/python3.8/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timeit-src>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'batched_dot_mul_sum' from '__main__' (unknown location)"
     ]
    }
   ],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/johnnydevriese/miniconda3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "aom                       3.2.0                he49afe7_2    conda-forge\n",
      "appnope                   0.1.2            py39h6e9494a_2    conda-forge\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\n",
      "backports                 1.0                        py_2    conda-forge\n",
      "backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\n",
      "blas                      1.0                         mkl  \n",
      "brotlipy                  0.7.0           py39h89e85a6_1003    conda-forge\n",
      "bzip2                     1.0.8                h0d85af4_4    conda-forge\n",
      "ca-certificates           2021.10.8            h033912b_0    conda-forge\n",
      "certifi                   2021.10.8        py39h6e9494a_1    conda-forge\n",
      "cffi                      1.15.0           py39he338e87_0    conda-forge\n",
      "chardet                   4.0.0            py39h6e9494a_2    conda-forge\n",
      "charset-normalizer        2.0.0              pyhd8ed1ab_0    conda-forge\n",
      "colorama                  0.4.4              pyh9f0ad1d_0    conda-forge\n",
      "conda                     4.10.3           py39h6e9494a_3    conda-forge\n",
      "conda-package-handling    1.7.3            py39h89e85a6_1    conda-forge\n",
      "cryptography              35.0.0           py39h209aa08_2    conda-forge\n",
      "debugpy                   1.5.1            py39h9fcab8e_0    conda-forge\n",
      "decorator                 5.1.0              pyhd8ed1ab_0    conda-forge\n",
      "entrypoints               0.3             pyhd8ed1ab_1003    conda-forge\n",
      "ffmpeg                    4.4.1                h79e7b16_0    conda-forge\n",
      "freetype                  2.10.4               h4cff582_1    conda-forge\n",
      "gettext                   0.19.8.1          hd1a6beb_1008    conda-forge\n",
      "gmp                       6.2.1                h2e338ed_0    conda-forge\n",
      "gnutls                    3.6.13               h756fd2b_1    conda-forge\n",
      "icu                       69.1                 he49afe7_0    conda-forge\n",
      "idna                      3.1                pyhd3deb0d_0    conda-forge\n",
      "ipykernel                 6.5.0            py39h71a6800_1    conda-forge\n",
      "ipython                   7.29.0           py39h71a6800_2    conda-forge\n",
      "jbig                      2.1               h0d85af4_2003    conda-forge\n",
      "jedi                      0.18.1           py39h6e9494a_0    conda-forge\n",
      "jpeg                      9d                   hbcb3906_0    conda-forge\n",
      "jupyter_client            7.0.6              pyhd8ed1ab_0    conda-forge\n",
      "jupyter_core              4.9.1            py39h6e9494a_1    conda-forge\n",
      "lame                      3.100             h35c211d_1001    conda-forge\n",
      "lcms2                     2.12                 h577c468_0    conda-forge\n",
      "lerc                      3.0                  he49afe7_0    conda-forge\n",
      "libcxx                    12.0.1               habf9029_0    conda-forge\n",
      "libdeflate                1.8                  h0d85af4_0    conda-forge\n",
      "libffi                    3.4.2                h0d85af4_5    conda-forge\n",
      "libiconv                  1.16                 haf1e3a3_0    conda-forge\n",
      "libpng                    1.6.37               h7cec526_2    conda-forge\n",
      "libsodium                 1.0.18               hbcb3906_1    conda-forge\n",
      "libtiff                   4.3.0                hd146c10_2    conda-forge\n",
      "libuv                     1.42.0               h0d85af4_0    conda-forge\n",
      "libvpx                    1.11.0               he49afe7_3    conda-forge\n",
      "libwebp-base              1.2.1                h0d85af4_0    conda-forge\n",
      "libxml2                   2.9.12               h7e28ab6_1    conda-forge\n",
      "libzlib                   1.2.11            h9173be1_1013    conda-forge\n",
      "llvm-openmp               12.0.1               hda6cdc1_1    conda-forge\n",
      "lz4-c                     1.9.3                he49afe7_1    conda-forge\n",
      "matplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge\n",
      "mkl                       2021.4.0           h89fa619_689    conda-forge\n",
      "mkl-service               2.4.0            py39h89e85a6_0    conda-forge\n",
      "mkl_fft                   1.3.1            py39h7ae3660_1    conda-forge\n",
      "mkl_random                1.2.2            py39h4d6be9b_0    conda-forge\n",
      "ncurses                   6.2                  h2e338ed_4    conda-forge\n",
      "nest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge\n",
      "nettle                    3.6                  hedd7734_0    conda-forge\n",
      "numpy                     1.21.2           py39h4b4dc7a_0  \n",
      "numpy-base                1.21.2           py39he0bd621_0  \n",
      "olefile                   0.46               pyh9f0ad1d_1    conda-forge\n",
      "openh264                  2.1.1                hfd3ada9_0    conda-forge\n",
      "openjpeg                  2.4.0                h6e7aa92_1    conda-forge\n",
      "openssl                   1.1.1l               h0d85af4_0    conda-forge\n",
      "parso                     0.8.2              pyhd8ed1ab_0    conda-forge\n",
      "pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\n",
      "pillow                    8.4.0            py39he9bb72f_0    conda-forge\n",
      "pip                       21.3.1             pyhd8ed1ab_0    conda-forge\n",
      "prompt-toolkit            3.0.22             pyha770c72_0    conda-forge\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\n",
      "pycosat                   0.6.3           py39h89e85a6_1009    conda-forge\n",
      "pycparser                 2.21               pyhd8ed1ab_0    conda-forge\n",
      "pygments                  2.10.0             pyhd8ed1ab_0    conda-forge\n",
      "pyopenssl                 21.0.0             pyhd8ed1ab_0    conda-forge\n",
      "pysocks                   1.7.1            py39h6e9494a_4    conda-forge\n",
      "python                    3.9.7           h1248fe1_3_cpython    conda-forge\n",
      "python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\n",
      "python.app                3                py39h9ed2024_0  \n",
      "python_abi                3.9                      2_cp39    conda-forge\n",
      "pytorch                   1.10.0                  py3.9_0    pytorch\n",
      "pyzmq                     22.3.0           py39h7fec2f1_1    conda-forge\n",
      "readline                  8.1                  h05e3726_0    conda-forge\n",
      "requests                  2.26.0             pyhd8ed1ab_0    conda-forge\n",
      "ruamel_yaml               0.15.80         py39h89e85a6_1006    conda-forge\n",
      "setuptools                59.1.1           py39h6e9494a_0    conda-forge\n",
      "six                       1.16.0             pyh6c4a22f_0    conda-forge\n",
      "sqlite                    3.36.0               h23a322b_2    conda-forge\n",
      "svt-av1                   0.8.7                he49afe7_1    conda-forge\n",
      "tbb                       2021.4.0             h940c156_1    conda-forge\n",
      "tk                        8.6.11               h5dbffcc_1    conda-forge\n",
      "torchvision               0.11.1                 py39_cpu    pytorch\n",
      "tornado                   6.1              py39h89e85a6_2    conda-forge\n",
      "tqdm                      4.62.3             pyhd8ed1ab_0    conda-forge\n",
      "traitlets                 5.1.1              pyhd8ed1ab_0    conda-forge\n",
      "typing_extensions         4.0.0              pyha770c72_0    conda-forge\n",
      "tzdata                    2021e                he74cb21_0    conda-forge\n",
      "urllib3                   1.26.7             pyhd8ed1ab_0    conda-forge\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\n",
      "wheel                     0.37.0             pyhd8ed1ab_1    conda-forge\n",
      "x264                      1!161.3030           h0d85af4_1    conda-forge\n",
      "x265                      3.5                  h940c156_1    conda-forge\n",
      "xz                        5.2.5                haf1e3a3_1    conda-forge\n",
      "yaml                      0.2.5                haf1e3a3_0    conda-forge\n",
      "zeromq                    4.3.4                he49afe7_1    conda-forge\n",
      "zlib                      1.2.11            h9173be1_1013    conda-forge\n",
      "zstd                      1.5.0                h582d3a0_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "! conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
      "                             [--epochs N] [--lr LR] [--gamma M] [--no-cuda]\n",
      "                             [--dry-run] [--seed S] [--log-interval N]\n",
      "                             [--save-model]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/johnnydevriese/Library/Jupyter/runtime/kernel-59506205-59ae-4a59-8704-3ff419da213d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    args = parser.parse_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.000393 after 405 batches\n",
      "==> Learned function:\ty = -9.48 x^1 +4.39 x^2 -1.07 x^3 -3.53 x^4 +3.16\n",
      "==> Actual function:\ty = -9.52 x^1 +4.48 x^2 -1.06 x^3 -3.55 x^4 +3.13\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "POLY_DEGREE = 4\n",
    "W_target = torch.randn(POLY_DEGREE, 1) * 5\n",
    "b_target = torch.randn(1) * 5\n",
    "\n",
    "\n",
    "def make_features(x):\n",
    "    \"\"\"Builds features i.e. a matrix with columns [x, x^2, x^3, x^4].\"\"\"\n",
    "    x = x.unsqueeze(1)\n",
    "    return torch.cat([x ** i for i in range(1, POLY_DEGREE+1)], 1)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Approximated function.\"\"\"\n",
    "    return x.mm(W_target) + b_target.item()\n",
    "\n",
    "\n",
    "def poly_desc(W, b):\n",
    "    \"\"\"Creates a string description of a polynomial.\"\"\"\n",
    "    result = 'y = '\n",
    "    for i, w in enumerate(W):\n",
    "        result += '{:+.2f} x^{} '.format(w, i + 1)\n",
    "    result += '{:+.2f}'.format(b[0])\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_batch(batch_size=32):\n",
    "    \"\"\"Builds a batch i.e. (x, f(x)) pair.\"\"\"\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random)\n",
    "    y = f(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Define model\n",
    "fc = torch.nn.Linear(W_target.size(0), 1)\n",
    "\n",
    "for batch_idx in count(1):\n",
    "    # Get data\n",
    "    batch_x, batch_y = get_batch()\n",
    "\n",
    "    # Reset gradients\n",
    "    fc.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = F.smooth_l1_loss(fc(batch_x), batch_y)\n",
    "    loss = output.item()\n",
    "\n",
    "    # Backward pass\n",
    "    output.backward()\n",
    "\n",
    "    # Apply gradients\n",
    "    for param in fc.parameters():\n",
    "        param.data.add_(-0.1 * param.grad)\n",
    "\n",
    "    # Stop criterion\n",
    "    if loss < 1e-3:\n",
    "        break\n",
    "\n",
    "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))\n",
    "print('==> Learned function:\\t' + poly_desc(fc.weight.view(-1), fc.bias))\n",
    "print('==> Actual function:\\t' + poly_desc(W_target.view(-1), b_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9464, 0.6891],\n",
      "        [0.1501, 0.2989],\n",
      "        [0.6019, 0.5568],\n",
      "        [0.8334, 0.2827],\n",
      "        [0.1098, 0.2141],\n",
      "        [0.0985, 0.8353],\n",
      "        [0.1616, 0.3116],\n",
      "        [0.2264, 0.0013],\n",
      "        [0.3426, 0.7077],\n",
      "        [0.1323, 0.4294]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(10, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.95 µs ± 11.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Calculate the projection matrix of x on the CPU\n",
    "H = x.mm( (x.t().mm(x)).inverse() ).mm(x.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "WGS84A = 6378137.0\n",
    "WGS84F = 1.0 / 298.257223563\n",
    "WGS84B = WGS84A - WGS84F * WGS84A\n",
    "\n",
    "x = 652954.1006\n",
    "y = 4774619.7919\n",
    "z = -2217647.7937\n",
    "\n",
    "\n",
    "\n",
    "def ecef2GeodeticJohnny(x, y, z, a, b):\n",
    "    e2 = (a*a - b*b) / (a*a) # first eccentricity squared\n",
    "    d = (a*a - b*b) / b\n",
    "    \n",
    "    # p2 = np.square(x) + np.square(y)\n",
    "    p2 = x * x + y * y\n",
    "    p = p2 * p2 \n",
    "    r = math.sqrt(p2 + z*z)\n",
    "    tu = b*z*(1 + d/r)/(a*p)\n",
    "    tu2 = tu*tu\n",
    "    cu3 = (1/math.sqrt(1 + tu2))**3\n",
    "    su3 = cu3*tu2*tu\n",
    "    tp = (z + d*su3)/(p - e2*a*cu3)\n",
    "    lat = math.atan(tp)\n",
    "    \n",
    "    lon = math.atan2(y,x)\n",
    "    \n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662 ns ± 4.45 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ecef2GeodeticJohnny(x, y, z, WGS84A, WGS84B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running pytorch on m1 gpu \n",
    "\n",
    "https://pytorch.org/docs/stable/notes/mps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnnydevriese/miniforge3/envs/pytorch-nightly/lib/python3.10/site-packages/torch/_tensor_str.py:103: UserWarning: The operator 'aten::bitwise_and.Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "    # Create a Tensor directly on the mps device\n",
    "    x = torch.ones(5, device=mps_device)\n",
    "    # Or\n",
    "    # x = torch.ones(5, device=\"mps\")\n",
    "    print(x)\n",
    "\n",
    "    # # Any operation happens on the GPU\n",
    "    # y = x * 2\n",
    "\n",
    "    # # Move your model to mps just like any other device\n",
    "    # model = YourFavoriteNet()\n",
    "    # model.to(mps_device)\n",
    "\n",
    "    # # Now every call runs on the GPU\n",
    "    # pred = model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pytorch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a8bcccfb183d1298694efece6cf41240378bc61621e95c864629a40c5876542"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
